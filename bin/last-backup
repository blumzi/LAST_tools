#!/bin/bash

#
# Files with this name pattern will
# - not be backed up
# - will not be removed after backup
# - will be removed if more than 36 hours have passed since the transfer succeeded
#
ignored_files='/LAST.*_sci_proc_(Image|Mask|PSF)'   # A 'grep -Ev' pattern

#
# Stamps a directory as "transfered"
# Removes previous (supposedly bogus) stamps 
# Syncs the .status file to the target
#
function stamp_as_transfered() {
    local src_dir="${1}"
    local dst_dir="${2}"
    local job_tag="${3}"

    local stat_file=${src_dir}/.status
    local stamp_line="$(date --iso-8601=seconds --utc) transfered"
    local file_type
    local ssh_flags=(-q -o "StrictHostKeyChecking accept-new")

    local time_stamp=$(grep -w "ready-for-transfer" ${stat_file} | tail -1 | cut -d' ' -f1)
    local seconds_from_ready=$(( $(date +%s) - $(date --date "${time_stamp}" +%s) ))
    stamp_line+=" # ${seconds_from_ready} seconds from ready-for-transfer"

    if [ ! -e ${stat_file} ]; then
        echo "${stamp_line}" > ${stat_file}
        message_success "${job_tag} Stamped \"${source}\" as \"transfered\"."
    else
        (
            grep -vw transfered ${stat_file}
            echo "${stamp_line}"
        ) > ${stat_file}.new
        mv ${stat_file}.new ${stat_file}
    fi
    chown ${user_name}.${user_group} ${stat_file}
    message_success "${job_tag} Stamped \"${source}\" as \"transfered\"."

    file_type=$( sudo -u ${user_name} ssh "${ssh_flags[@]}" ${backup_user}@${backup_host} "stat -c %F ${dst_dir#*:} 2>/dev/null" )
    if [ "${file_type}" = directory ]; then
        message_info "${job_tag} Copying .info and .status to ${dst_dir} ..."
        sudo -u ${user_name} scp -r "${ssh_flags[@]}" ${info_dir} ${dst_dir}
        sudo -u ${user_name} scp "${ssh_flags[@]}" ${stat_file} ${dst_dir}
    elif [ "${file_type}" = "regular file" ]; then
        message_failure "${job_tag} Not copying .status and .info to ${dst_dir}, ${dst_dir} IS A REGULAR FILE"
    elif [ ! "${file_type}" ]; then
        message_failure "${job_tag} Not copying .status and .info to ${dst_dir}, ${dst_dir} DOES NOT EXIST"
    fi
}

function cleanup() {
    local failures=( $(if [ -s ${tmp}/.failures ]; then cat ${tmp}/.failures 2>/dev/null; fi) )
    local running_processes=( $(jobs -pr) )

    if [ ${#running_processes[*]} -eq 0 ]; then
        if (( ${#failures[*]} == 0 )); then
            # message_success "All chunks have been synchronized"
            :
        else
            failures=( $(list_sort "${failures[@]}" ) )
            message_fatal "Chunks ${failures[*]} have failed to synchronize!"
        fi
    else
        message_info "Killing running process(es): ${running_processes[*]}"
        2>/dev/null kill -9 ${running_processes[*]} 
    fi
    /bin/rm -rf ${tmp}
    exit 0
}

trap cleanup SIGHUP SIGINT


PROG=$(basename ${0})
source /etc/profile.d/last.sh

module_include lib/message
module_include lib/util
module_include lib/list
module_include lib/backup
module_include lib/user

util_log_invokation ${*}

# defaults
identity=
default_nproc=1
basic_exclusion_pattern="--exclude '*/raw'"
extended_exclusion_pattern="--exclude '*_sci_proc_Image_*' --exclude '*_sci_proc_Mask_*' --exclude '*_sci_proc_PSF_*'"
#rsync_extra_args="--exclude '*/raw' --exclude '*_sci_proc_Image_*' --exclude '*_sci_proc_Mask_*' --exclude '*_sci_proc_PSF_*'"
rsync_extra_args="${basic_exclusion_pattern} ${extended_exclusion_pattern}"
rsync_info_args="--info=STATS0 --info=FLIST0"
quiet=false


function usage() {
    cat <<- EOF

    Usage: ${PROG} [flags] -s|--source|-f|--from <source-directory> [ -t|--to|--target [<user@host>:]<target-directory> ]

    Either one or more <source-directories> may be specified with --source.
    If no <source-directories> were specified, all the directories named */proc/* under /$(hostname -s)/data[12] will
     be backed up.

    Every <source-directory> will be recursivelly synchronized with the <target-directory>.
    Both source and target may reside on the current machine.

    This utility:
    - Uses an rsync 'dry-run' to get the list of out-of-date files
       between the source and the target directories (a workload list).
    - Splits the workload into chunks (maximum as many as the number of parallel processes)
    - Starts the relevant number of rsync processes, one-per-chunk
    - Waits for all the rsync processes to end.

    Exclusion pattern:
        ${rsync_extra_args}

    Flags:
     -h|--help        - Show usage and exit
     -a|--all         - Backup all /$(hostname -s)/data[12]/archive/*/proc/* directories (default)
     -q|--quiet       - Be quiet
     -s|--source      - Specifies the source-directory
     -f|--from        - Specifies the source-directory
     -t|--to|--target - Specifies the target-directory (default: ${backup_default_target})
     -p|--processes   - Specifies the number of processes to use (default: ${default_nproc})
     -x|--extra       - Specifies additional arguments to rsync (e.g. --exclude=...)
     -c|--check       - Check if the source directory was backed up
     -r|--remove      - Remove source directory if it was backed up (only works with -c|--check or -C|--check-all)
     -F|--force       - Force removal of local directory (only works with -r|--remove)
     -C|--check-all   - Same as -c|--check but for all the local directories
     -j|--jobs N      - Run upto N jobs (default: 5) in parallel
     -S|--status      - Show all the rsync process currently in progress
     -T|--total       - Total backup, exclusion pattern only: ${basic_exclusion_pattern}
     -k|--kill        - Kills all existing ${PROG} processes

EOF
}

OPTS=$( getopt -o 'Sqs:f:t:hi:p:xcrCFaj:Tkl' --long "list,kill,status,jobs,all,quiet:,help,extra:,processes:,identity:,force,source:,from:,to:,target:,check,remove,check-all,total" -n "${PROG}" -- "$@" 2> /tmp/.getopt-err )
if [ $? -ne 0 ]; then
    if [ -r /tmp/.getopt-err ]; then
        message_failure "$(< /tmp/.getopt-err)"
        /bin/rm -f /tmp/.getopt-err
    fi
    exit 1
fi
eval set -- "${OPTS}"

function status() {
    local lines pids pid

    pids=( $( pgrep ${PROG} ) )
    if [ ${#pids[*]} -eq 0 ]; then
        message_info "No active ${PROG} processes."
        return
    fi
    module_include lib/ansi

    mapfile lines < <(pgrep -alf 'sudo.*rsync')
    if [ ${#lines[@]} -eq 0 ]; then
        message_info "No last-backup processes"
        return
    fi

    for line in "${lines[@]}"; do
        #echo "line: ${line}" 
        local -a words=( ${line} )
        local word visit from dest

        pid=${words[0]}
        local parent_process=$( pstree -aclsp ${pid} | awk -v pid=${pid} '
            {
                if (match($0, /.*last-backup.*/)) {
                    print parent_process
                    exit
                }
                sub(/.*`-/, "")
                split($1, arr, ",")
                parent_pid = arr[2]
                parent_cmd = arr[1] 
                for (i = 2; i <= NF; i++)
                    parent_cmd = parent_cmd " " $i
                parent_process = "[" parent_pid "] " parent_cmd
            }
        ')

        for word in ${words[*]}; do
            if [[ ${word} == /last* ]]; then
                visit=${word#*archive/}
                from="${word%${visit}}"
                visit="${visit%/}"
            fi


            if [[ ${word} == ${backup_user}@${backup_host}* ]]; then
                dest="${word%${visit}}"

                message_success "Visit       $(ansi_underline ${visit})"
                message_info    "Source      ${from%/}/$(ansi_underline ${visit})"
                message_info    "Destination ${dest%/}/$(ansi_underline ${visit})"
                message_info    "Initiator   ${parent_process}"
                echo ""
                break
            fi
        done
    done
}

total=false
check=false
check_all=false
backup_all=true
remove=false
force=false
sources=()
target=
status_only=false
help_only=false
kill_only=false
list_sources=false
jobs=1

while true; do
    case "${1}" in

    -l|--list)
        list_sources=true
        shift 1
        ;;

    -k|--kill)
        kill_only=true
        shift 1
        ;;

    -S|--status)
        status_only=true
        shift 1
        ;;

    -j|--jobs)
        jobs=${1}
        shift 2
        ;;

    -a|--all)
        backup_all=true
        shift 1
        ;;

    -C|--check-all)
        check_all=true
        shift 1
        ;;

    -c|--check)
        check=true
        shift 1
        ;;

    -r|--remove)
        remove=true
        shift 1
        ;;

    -F|--force)
        force=true
        shift 1
        ;;

    -q|--quiet)
        quiet=true
        shift 1
        ;;

    -s|--source|-f|--from)
        source="$(realpath ${2})"
        if [ $? -ne 0 ]; then
            message_fatal "Bad source \"${2}\", no such directory"
            exit 1
        fi
        sources+=( ${source} )
        shift 2
        ;;

    -t|--target|--to)
        if [[ ${2} != *@*:* ]]; then
            message_fatal "Bad target \"${2}\". It must have the format user-name@host-name:path-to-top-directory"
            exit 1
        fi
        target="${2}"
        shift 2
        ;;

    -h|--help)
        help_only=true
        shift 1
        ;;

    -i|--identity)
        identity="${2}"
        shift 2
        ;;
    
    -p|--processes)
        nprocs="${2}"
        shift 2
        ;;
    
    -x|--extra)
        rsync_extra_args+=" ${2}"
        shift 2
        ;;

    -T|--total)
        total=true
        shift 1
        ;;

    --)
        shift 1
        break
        ;;

    -*)
        message_error "Invalid flag '${1}'"
        usage
        exit 1
        ;;

    esac
done

if ${total}; then
    rsync_extra_args="${basic_exclusion_pattern}"
fi

if ${help_only}; then
    usage
    exit 0
fi

if [ ! "${target}" ]; then
    target="${backup_default_target}"
fi

if ${quiet}; then
    export LAST_TOOL_QUIET=true
fi


backup_set_target "${target}"

function visit_is_beeing_backed_up() {
    local searched_visit="${1}"
    local lines

    mapfile lines < <(pgrep -alf 'sudo.*rsync')
    for line in "${lines[@]}"; do
        local -a words=( ${line} )
        local word visit from to

        for word in ${words[*]}; do
            if [[ ${word} == /last* ]]; then
                visit=${word#*archive/}
                visit="${visit%/}"
                if [ "${searched_visit}" = "${visit}" ]; then
                    return 0
                fi
            fi
        done
    done
    return 1
}

function kill_all_backups() {
    local sudo_pids=( $(pgrep -f 'sudo.*rsync') )
    local sudo_pid pid descendants

    for sudo_pid in ${sudo_pids[*]}; do
        descendants=( $(pstree -a -s -p ${sudo_pid} | awk '/last-backup/ { found = 1 }; found { sub(/^[^,]*,/, "", $1); print $1}'|tac ) )
        for pid in ${descendants[*]}; do
            kill ${pid}
        done
    done
}

if ${kill_only}; then
    kill_all_backups
    exit 0
fi

if ${status_only}; then
    status
    exit 0
fi

if [ ! "${nprocs}" ]; then
    nprocs=${default_nproc}
fi

tmp=$(mktemp -d)
chmod 755 ${tmp}
cd ${tmp}
info_dir=${tmp}/.info-$(date +%Y-%m-%d_%H-%M-%S)
mkdir -p ${info_dir}

files_list=files

if ${check}; then
    backup_check_one "${source}"
    exit 0
fi

if ${check_all}; then
    backup_check_all
    exit 0
fi

#pids=( $(ps -alf | grep "bash.*${PROG}" | grep -vw grep | grep -vw ${$} | awk '{print $4}') )
#if [ ${#pids[*]} -ne 0 ]; then
#    message_failure "There already is/are running ${PROG} process(es) (pid(s): ${pids[*]}), only one allowed!"
#    exit 1
#fi

if [ "${#sources[@]}" -eq 0 ]; then     # no sources were selected with --source
    if ${backup_all}; then
        message_info "Detecting sources ..."
        all_sources=( $( find /$(hostname -s)/data[12]/archive -type d -path '*/proc/*' | grep -v '_re/' | sort ) )
        for source in ${all_sources[*]}; do
            stat_file=${source}/.status
            if [ -r ${stat_file} ] && grep -qw ready-for-transfer ${stat_file} && ! grep -qw transfered ${stat_file}; then
                sources+=( ${source} )
            fi
        done
        message_info "Detected ${#sources[*]} ready but not transfered sources"
    fi
fi

# Neither manually specified nor automatically found sources
if [ "${#sources[@]}" -eq 0 ]; then
    message_info "Nothing to backup, bye!"
    exit 0
fi

if ${list_sources}; then
    for source in ${sources[*]}; do
        message_info "${source}"
    done
    exit 0
fi

function remove_if_transfered_and_aged() {
    local directory="${1}"
    local tag="${2}"
    local time_stamp hours_from_creation status_file transfered=false
    local aging_hours=36

    status_file=${directory}/.status
    if [ ! -r ${status_file} ]; then
        message_warning "Missing ${status_file}"
        return
    fi

    if grep -wq transfered ${status_file}; then
        transfered=true
    fi
    time_stamp=$(grep -w "ready-for-transfer" ${status_file} | tail -1 | cut -d' ' -f1)
    hours_from_creation=$(( ( $(date +%s) - $(date --date "${time_stamp}" +%s) ) / 3600 ))

    if ${transfered} && [ ${hours_from_creation} -ge ${aging_hours} ]; then
        message_success "${tag} ${hours_from_creation} hours have passed since transfer (more than ${aging_hours}), removing \"${directory}\" ..."
        /bin/rm -rf ${directory}
    fi
}

function is_being_backed_up() {
    pgrep -f "^rsync .*${1}.*"
}

function backup_one_source() {
    local data_dir=${1}
    local job_tag="[${job_id}/${#sources[@]}]"
    local backup_target_dir_full_path visit


    if [[ "${data_dir}"  == */archive/* ]]; then
        data_dir="${data_dir#*/archive/}"
        local backup_process=$(is_being_backed_up "${data_dir}")

        if [ "${backup_process}" ]; then
            message_info "${data_dir} is already being backed up by pid ${backup_process}"
            return
        fi
        backup_target_dir_full_path=${backup_target}/${data_dir}
    else
        backup_target_dir_full_path=${backup_target}
    fi

    echo ''
    message_info "${job_tag} Source: \"${source}\""
    message_info "${job_tag} Target: \"${backup_target_dir_full_path}\""

    message_info "${job_tag} Gathering list of files ..."

    #
    # TODO: the source and destination MUST be of the same type, either FILE or DIRECTORY.
    #  If the destination exists but is not of the same type, MAYBE remove it first ?!?
    #
    sudo -u ocs rsync -e 'ssh -o "StrictHostKeyChecking accept-new"' -av ${rsync_info_args} --dry-run ${rsync_extra_args} ${source}/ ${backup_target_dir_full_path} 2>rsync_errors | grep -v '\.\/' | grep -v 'created directory' | grep -Ev "${ignored_files}" > ${files_list}
    if [ ${PIPESTATUS[0]} -ne 0 ]; then
        if [ -s rsync_errors ]; then
            while read line; do
                message_error "${job_tag} rsync error:  ${line}"
            done < rsync_errors
        fi
        /bin/rm rsync_errors
        message_failure "${job_tag} Failed getting files list from ${backup_target_dir_full_path}"
        return
    fi

    if (( $(wc -l < ${files_list}) == 0 )); then
        message_success "${job_tag} The source and target directories are synchronized"
        stamp_as_transfered "${source}" "${backup_target_dir_full_path}" "${job_tag}" "${job_tag}"

        if ${remove} && ${force}; then
            message_success "${job_tag} Removing \"${source}\" ..."
            remove_if_transfered_and_aged ${source} "${job_tag}"
        fi

        return
    fi

    message_info "${job_tag} Splitting workload among ${nproc} processes ..."
    nlines=$( awk -v lines=$(wc -l < ${files_list}) -v nprocs=${nprocs} 'BEGIN {print int(lines/nprocs) + 1}' )
    split --lines=${nlines} < ${files_list}
    cp ${files_list} ${info_dir}/${files_list}
    chunks=( x?? )

    sudo -u ocs ssh -o "StrictHostKeyChecking accept-new" ${backup_user}@${backup_host} mkdir -p ${backup_target_dir_full_path#*:}

    local chunk_info_prefix
    for ((i = 0; i < ${#chunks[*]}; i++)); do
        (
            message_info "${job_tag} Synchronizing chunk #$((i+1)) (of ${#chunks[*]}) ..."
            chunk_info_prefix="${info_dir}/chunk#$((i + 1))"
            stat_file=${chunk_info_prefix}.status
            echo "sudo -u ocs rsync -aRz --stats --times ${rsync_extra_args} --files-from=${chunks[${i}]} ${source}/ ${backup_target_dir_full_path} 2>/dev/null ) > ${stat_file}" > "${chunk_info_prefix}.cmd"
            cp ${chunks[${i}]} "${chunk_info_prefix}.files"
            (sudo -u ocs rsync -aRz --stats --times ${rsync_extra_args} --files-from=${chunks[${i}]} ${source}/ ${backup_target_dir_full_path} 2>/dev/null ) > ${stat_file}
            status=${?}
            echo "exit status: ${status}" >> ${stat_file}

            if [ "${status}" ] && [ ${status} -eq 0 ]; then
                Speedup=$(grep speedup ${stat_file}  | cut -d' ' -f8)
                    Bps=$(grep '^sent ' ${stat_file} | cut -d' ' -f9 | tr -d ,)
                   Mbps=$(awk -v Bps=${Bps} 'BEGIN { printf "%.3f\n", Bps / 125000 }')
                message_success "${job_tag} Chunk #$((i+1)) (of ${#chunks[*]}) succeeded (${Mbps} Mbps, speedup ${Speedup})"
            else
                # rsync returns 20 when killed
                if [ "${status}" != 20 ]; then
                    message_failure "${job_tag} Chunk #$((i+1)) (of ${#chunks[*]}) failed with status: ${status}"
                fi
                echo ${i} >> ${tmp}/.failures
            fi
        ) &
    done

    wait

    if [ ! -e ${tmp}/.failures ]; then
        # the backup succeeded
        stamp_as_transfered "${source}" "${backup_target_dir_full_path}" "${job_tag}"

        if ${remove} && ${force}; then
            message_success "${job_tag} Removing \"${source}\" ..."
            remove_if_transfered_and_aged ${source} "${job_tag}"
        fi
    fi
}

running_jobs=0
job_id=0
for source in "${sources[@]}"; do
    visit=${source#*/archive/}

    if ! grep -qw ready-for-transfer ${source}/.status || grep -wq transfered ${source}/.status; then
        continue
    fi

    if visit_is_beeing_backed_up ${visit}; then
        message_info "Vist ${visit} is already being backed up, skipping."
    else
        backup_one_source "${source}" &
        (( running_jobs++ ))
        (( job_id++ ))

        if ((running_jobs >= jobs)); then
            wait -n
            ((running_jobs--))
        fi
    fi
done

cleanup
